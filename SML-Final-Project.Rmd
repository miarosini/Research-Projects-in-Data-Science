---
title: "SML310 Final Project"
author: "Mia Rosini"
date: "December 1st, 2020"
output:
  pdf_document: default
  html_notebook: default
  word_document: default
  rmarkdown::github_document
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library("readxl")
library(tidyverse)
library(dplyr)
library(sjPlot)
library(stargazer)
library(ggthemes)
library(lme4)
library(jtools)
library(car)
library(readr)
library(caTools)
library(ggplot2)
library(e1071)
library(naivebayes)
library(caret)
require(knitr) # for better tables in the Markdown
require(caTools) # for sample.split function
require(ROCR) # for the ROC curve 
require(caret) # for confusionmatrix() 
require(ROSE) # for downsampling
require(rpart) # for decision tree 
suppressWarnings(library(effects))

output_type <- ifelse(knitr::is_latex_output(),  
                      "latex", "html")   
```

### Scope of Inference: 
The scope of inference for this report is based on the data used, in that scope would lie within the United States’ child detentions reported by the CBP Office of Field Operations and the CBP Border Patrol between mid-January 2017 and late January 2020. 

```{r table, echo = FALSE, message = FALSE, results='asis'}
#Download DataSet 
detention_minors <- read_excel("detention_of_minors.xlsx")
detention_minors$year = substr(detention_minors$date_in,1,4) 
detention_minors$year = suppressWarnings(as.numeric(detention_minors$year))

#Dataset of Year, Gender, Citizenship, Age Group, Hours in Custody, Border, Sector
condense <- detention_minors %>% select(year, gender, citizenship, age_group, hours_in_custody, border, sector)

#Create new Column: 72 hours? 1 if yes, 0 if No 
condense$over_72_hours <- "Set"
condense$hours_in_custody = suppressWarnings(as.numeric(condense$hours_in_custody))
condense$over_72_hours[condense$hours_in_custody > 72.0] <- "1"
condense$over_72_hours[condense$hours_in_custody <= 72.0] <- "0"
condense$over_72_hours <- suppressWarnings(as.numeric(condense$over_72_hours))

#Condensed Dataset of Year, Gender, Citizenship, Age Group, Hours in Custody, Over_72_hours
Final <- condense %>% select(year, gender, citizenship, age_group, border, over_72_hours) %>% na.omit()
Final <- Final %>% na.omit() 
Final$region_of_origin <- suppressWarnings(Final$region_of_origin %>% na.omit())

#Remove "Years" 
Final$age_group <- substr(Final$age_group,1,nchar(Final$age_group)-6) #Age Group 

#Make variables factors 
Final$gender[Final$gender == "Female"] <- 1 #Female is 1 
Final$gender[Final$gender == "Male"] <- 0 #Male is 0 
Final$gender <- suppressWarnings(as.numeric(Final$gender))
Final$gender <- suppressWarnings(as.character(Final$gender))

Final$age_group[Final$age_group == "0-1"] <- 1 #Change to age group 
Final$age_group[Final$age_group == "1-2"] <- 2 
Final$age_group[Final$age_group == "3-5"] <- 3 
Final$age_group[Final$age_group == "6-8"] <- 4 
Final$age_group[Final$age_group == "9-11"] <- 5 
Final$age_group[Final$age_group == "12-14"] <- 6
Final$age_group[Final$age_group == "15-18"] <- 7
Final$age_group <- suppressWarnings(as.character(Final$age_group))

#Merge Regions Dataset 
regions <- read_excel("Regions_.xlsx")
Final <- merge(regions, Final)

Final <- Final %>% select(-citizenship)
Final <- Final %>% select(year, gender, age_group, region_of_origin, border, over_72_hours)

#Remove Missing Values
Final <- Final %>% na.omit()
suppressWarnings(Final[Final$region_of_origin == "NA",] <- as.numeric(Final$region_of_origin == "NA"))
Final <- Final[Final$region_of_origin != "0",]
Final <- Final[Final$age_group != "",]

#Model, Logistic Regression
Final$region_of_origin <- suppressWarnings(as.factor(Final$region_of_origin))
Final$region_of_origin <- relevel(Final$region_of_origin, ref = "Mexico")
model <- glm(over_72_hours ~ year + gender + age_group + region_of_origin, data = Final)

stargazer(model, 
         type = output_type,
         font.size = "footnotesize",
         header = FALSE) # turn off message about package
```
\newpage

```{r, fig.width = 6, fig.height = 4}
plot(allEffects(model)[1], xlab = "Year", ylab = "Over 72 Hours Probability", 
     main = "Plot 1: Year Effect Plot") 
```

```{r, fig.width = 6, fig.height = 4}
plot(allEffects(model)[2], xlab = "Gender (1 = Female)", ylab = "Over 72 Hours Probability", 
     main = "Plot 2: Gender Effect Plot")
```

```{r, fig.width = 6, fig.height = 4}
plot(allEffects(model)[3], xlab = "Age Group", ylab = "Over 72 Hours Probability", 
     main = "Plot 3: Age Group Effect Plot")
```

```{r, fig.width = 6, fig.height = 4}
plot(allEffects(model)[4], xlab = "Region of Origin", ylab = "Over 72 Hour Probability", 
     main = "Plot 4: Region of Origin Effect Plot", axes = list(grid = TRUE, x = list(rotate = 60)))
```
\newpage


```{r}
#gender over years
gender_year <- Final %>% group_by(year, gender) %>% select(year, gender) %>% count()

ggplot(data = gender_year, aes(x = year, y = n, color = gender)) + geom_line() + geom_point() + labs(x = "Year", y ="Number of Immigrants", title = "Immigrant Children Held by Gender" ) 
```

```{r}
#age group by year
gender_agegroup <- Final %>% group_by(year, age_group) %>% select(year, age_group) %>% count()

gender_agegroup
ggplot(data = gender_agegroup, aes(x = year, y = n, color = age_group)) + geom_line() + geom_point() + labs(x = "Year", y ="Number of Immigrants", title = "Immigrant Children Held by Age Group" ) 
```

```{r}
#held over time by year
Final$over_72_hours <- as.character(Final$over_72_hours)
gender_overtime <- Final %>% group_by(year, over_72_hours) %>% select(year, over_72_hours) %>% count()

ggplot(data = gender_overtime, aes(x = year, y = n, color = over_72_hours)) + geom_line() + geom_point() + labs(x = "Year", y ="Number of Immigrants", title = "Immigrant Children Held by Overtime Status" ) 
```

```{r}
#held over time by region of origin 
region_year <- Final %>% group_by(year, region_of_origin) %>% select(year, region_of_origin) %>% count()

ggplot(data = region_year, aes(x = year, y = n, color = region_of_origin)) + geom_line() + geom_point() + labs(x = "Year", y ="Number of Immigrants", title = "Immigrant Children Held by Region of Origin" ) 
```





### Naive Bayes Classification Model: 

Next, a naive bayes classification predictive model was created to predict overtime at a detention center based on immigrant characteristics with the code below. A contingency table for the training data and the test data was generated. Both the performance (accuracy) on the test and training datasets was 65%. 

```{r}
Final1 <- Final

#Convert everything in Final1 to factor
Final1[] <- lapply(Final1, factor)

#Train and Test Sets 
set.seed(1000000)
sample = sample.split(Final1, SplitRatio = .7)
train = subset(Final1, sample == TRUE)
test  = subset(Final1, sample == FALSE)

#Model 
NBclassifier = naiveBayes(over_72_hours ~ ., data = train)
```

```{r}
#Prediction on training and test sets
print_results=function(model){
  trainPred = predict(model, newdata = train, type = "class")
  trainTable=table(train$over_72_hours, trainPred)
  testPred=predict(NBclassifier, newdata=test, type="class")
  testTable=table(test$over_72_hours, testPred)
  trainAcc=(trainTable[1,1]+trainTable[2,2])/sum(trainTable)
  testAcc=(testTable[1,1]+testTable[2,2])/sum(testTable)
  message("Contingency Table for Training Data")
  print(trainTable)
  message("Contingency Table for Test Data")
  print(testTable)
  message("Accuracy")
  print(round(cbind(trainAccuracy=trainAcc, testAccuracy=testAcc),3))
}

print_results(NBclassifier)
```

### Logistic Regression Classification Model: 

Next, a logistic regression classification model was created. With this model, the accuracy on the test data was 67% and the accuracy on the training data was 67%. The Naive Bayes and the Logistic Regression models both had a similar accuracy scores. For both the test and training set, the logistic regression classification model does a better job of accurately predicting those immigrant children kept less than 72 hours, compared to its predictions of more than 72 hours. This is most likely due to the imbalanced dataset, with 344594 data points of immigrants kept fewer than 72 hours and 168384 kept longer than 72 hours. Additionally, the accuracy score of 65% seems likely as there are many other factors that can contribute to whether an immigrant child is detained longer than 72 hours. 

```{r }
#Making classification model 
names <- c(2,3,4,5)
Final[,names] <- lapply(Final[,names] , factor)

Final <- Final %>% select(year, gender, age_group, region_of_origin, over_72_hours)

set.seed(3456)
#Create training and test sets
spl = sample.split(Y = Final$over_72_hours, SplitRatio = 0.7)
train = subset(Final, spl == TRUE)
test = subset(Final, spl == FALSE)

#Building Logistic Regression Model
model = glm(over_72_hours ~ ., family = "binomial", data = train)
```

```{r}
#Baseline accuracy
prop.table(table(train$over_72_hours))
```

```{r }
#Evaluation of Model Performance on the training set:
#Predictions on the training set
predict_train = predict(model, data = train, type = "response")
train <- train %>% na.omit()
```

```{r}
#Confusion Matrix on Training Data
table(train$over_72_hours, predict_train > 0.5)
```

```{r}
#Accuracy
(240544+429)/nrow(train) 
```

```{r }
#Evaluate model perforamnce on the test set
test <- test %>% na.omit()

#Predictions on the test set
predict_test = predict(model, newdata = test, type = "response")
```

```{r}
#Confusion Matrix on Training Data
table(test$over_72_hours, predict_test > 0.5)
```

```{r}
#Accuracy of Model on Test Data
(103095 + 181)/nrow(test) 
```

### Logistic Regression Classification Model: Undersampling

Last, a logistic regression classification model was created with a balanced dataset. A balanced dataset was achieved through undersampling so the number of data points in which over_72_hours = 1 and over_72_hours = 0 were the same. The accuracy score remained around the same. The area under the ROC curve was 0.629. 

```{r}
train_index <- sample.split(Y = Final$over_72_hours , SplitRatio = 0.7)

train_data <- Final[train_index, ]
test_data <- Final[!train_index, ]

#Logistic models Models
logit_model <- glm(data = train_data ,
                   formula = over_72_hours~. ,
                   family = "binomial" )

logit_pred <- predict(object = logit_model,
                      newdata = test_data ,
                      type = "response" )

#Create a balanced dataset
data_rose <- ROSE(over_72_hours ~., data = train, seed = 1)$data

#train logistic regression on balanced data
rose_model <- glm(over_72_hours ~., data = data_rose, family = "binomial")

rose_pred <- predict(rose_model, newdata = test_data, 
                     type = "response")

#predict
roc_pred <- prediction(predictions = rose_pred, labels = test_data$over_72_hours)
roc_perf <- performance(roc_pred, "tpr", "fpr")

#create ROC curve 
roc.curve(test_data$over_72_hours, logit_pred)
```

## 6 DISCUSSION AND LIMITATIONS

There are limitations to this study. First, no causal claims between immigrant children characteristics and being kept overtime in a detention facility can be made because there was no randomized treatment nor administered randomization. In addition, this study's findings cannot be extrapolated outside of the years 2017 to 2020. Instead, this study confirms correlations between certain immigrant characteristics and the odds of being detained overtime. This study confirms that during Donald Trump's presidency, thousands of immigrant children were kept over the 72 hour limit at detention facilities, and further supports the theory that Trump disregarded the human rights of thousands of immigrants and their children. The classification models built also need to be used with discretion because of their accuracy scores around 65%. 

## 7 CONCLUSION

Under the Trump administration, children were held in cages, lived in freezing temperatures, and were separated from their parents. Trump not only failed to provide the basic standards of care immigrants were required to receive, but also failed to respect basic human rights. With the limited data available from 2017 to 2020, this study has completed data analysis to expand on the existing literature centered on immigration policy under President Trump. 

Based on the results of this study, it is clear that several immigrant children characteristics increase the log odds of being detained over the 72 hour limit. Year, gender, age group, and region of origin all impact the chance of overtime. Specifically, an immigrant child who is female, 6-8 years old, kept in the year 2020, and from Central America has the highest log odds of being detained longer than the legal 72 hour time limit. This thus supports the theory that immigrant children of certain nationalities, genders, and ages are more likely to be kept over the 72 hours than others. 

The classification models built allow predictions to be made on the likelihood of an immigrant child being kept over the 72 hour time limit in detention facilities. Although these predictions may not be extrapolated beyond the years 2017 to 2020 and United States immigrants, there remains value in giving policymakers an idea of the demographics of immigrant children likely to be kept overtime in detention facilities. This information would allow policymakers in the Biden administration to determine which groups of immigrants they need to focus their attention on to quickly reunify families and create a more humane and efficient detention system. With President-Elect Biden's administration entering the White House, these findings can help inform their immigration policies.

## 8 BIBLIOGRAPHY

“Adding Weights to Logistic Regression for Imbalanced Data.” Cross Validated, 1 Sept. 2015, stats.stackexchange.com/questions/164693/adding-weights-to-logistic-regression-for-imbalanced-data. 

Ashkiani, Shahin. “Study of Class Imabalance Problems.” RPubs, rpubs.com/Shaahin/im_class_p1. 

“Change the y Axis on Effect Plot in R.” Stack Overflow, 1 Feb. 1967, stackoverflow.com/questions/47613064/change-the-y-axis-on-effect-plot-in-r. 

Ford, Clay. “University of Virginia Library Research Data Services + Sciences.” Research Data Services + Sciences, 2020, data.library.virginia.edu/visualizing-the-effects-of-logistic-regression/. 

“Imbalanced Classification Problems in R.” Analytics Vidhya, 5 July 2020,

www.analyticsvidhya.com/blog/2016/03/practical-guide-deal-imbalanced-classification-problems/. 

Khan, Riaz. “Naive Bayes Classifier: Theory and R Example.” RPubs, South Dakota State University, 20 Dec. 2017, rpubs.com/riazakhan94/naive_bayes_classifier_e1071. 
https://rpubs.com/riazakhan94/naive_bayes_classifier_e1071

Loynes, Christopher. “How to Create Naive Bayes in R for Numerical and Categorical Variables.” Stack Overflow, 1 Jan. 2017, stackoverflow.com/questions/47514017/how-to-create-naive-bayes-in-r-for-numerical-and-categorical-variables. 

Maklin, Cory. “Random Forest In R.” Medium, Towards Data Science, 30 July 2019, towardsdatascience.com/random-forest-in-r-f66adf80ec9. 

Narea, Nicole.“Trump Showed No Regret over Family Separations during the Presidential Debate,” Vox, October 22, 2020, https://www.vox.com/2020/10/22/21529710/trump-debate-family-separations.

Calderón, Andrew & Flagg, Anna.“500,000 Kids, 30 Million Hours: Trump’s Vast Expansion of Child Detention,” The Marshall Project, October 30, 2020, https://www.themarshallproject.org/2020/10/30/500-000-kids-30-million-hours-trump-s-vast-expansion-of-child-detention.

Villa, Lissandra.“President Trump Won’t Say How 545 Migrant Children Still Separated From Their Parents Will Be Reunited,” Time, accessed November 9, 2020, https://time.com/5903225/donald-trump-family-separation-debate/.

## 9 APPENDIX

### 1. Data Cleaning

```{r table3, results='asis'}
#Download DataSet 
detention_minors <- read_excel("detention_of_minors.xlsx")
detention_minors$year = substr(detention_minors$date_in,1,4) 
detention_minors$year = suppressWarnings(as.numeric(detention_minors$year))

condense <- detention_minors %>% select(year, gender, citizenship, age_group, 
                                        hours_in_custody, border, sector)

#Create new Column: 72 hours? 1 if yes, 0 if No 
condense$over_72_hours <- "Set"
condense$hours_in_custody = suppressWarnings(as.numeric(condense$hours_in_custody))
condense$over_72_hours[condense$hours_in_custody > 72.0] <- "1"
condense$over_72_hours[condense$hours_in_custody <= 72.0] <- "0"
condense$over_72_hours <- suppressWarnings(as.numeric(condense$over_72_hours))

#Condense Dataset 
Final <- condense %>% select(year, gender, citizenship, age_group, 
                             border, over_72_hours) %>% na.omit()
Final <- Final %>% na.omit()
Final$region_of_origin <- suppressWarnings(Final$region_of_origin %>% na.omit())

#Remove "Years" 
Final$age_group <- substr(Final$age_group,1,nchar(Final$age_group)-6) #Age Group 

#Make variables 
Final$gender[Final$gender == "Female"] <- 1 #Female is 1 
Final$gender[Final$gender == "Male"] <- 0 #Male is 0 
Final$gender <- suppressWarnings(as.numeric(Final$gender))
Final$gender <- suppressWarnings(as.character(Final$gender))

Final$age_group[Final$age_group == "0-1"] <- 1 #Change to age group 
Final$age_group[Final$age_group == "1-2"] <- 2 
Final$age_group[Final$age_group == "3-5"] <- 3 
Final$age_group[Final$age_group == "6-8"] <- 4 
Final$age_group[Final$age_group == "9-11"] <- 5 
Final$age_group[Final$age_group == "12-14"] <- 6
Final$age_group[Final$age_group == "15-18"] <- 7
#Final$age_group <- as.numeric(Final$age_group)
Final$age_group <- suppressWarnings(as.character(Final$age_group))

#Merge Regions 
regions <- read_excel("Regions_.xlsx")
Final <- merge(regions, Final)

Final <- Final %>% select(-citizenship)
Final <- Final %>% select(year, gender, age_group, region_of_origin, border, over_72_hours)

#Remove Missing Values
Final <- Final %>% na.omit()
suppressWarnings(
  Final[Final$region_of_origin == "NA",] <- as.numeric(Final$region_of_origin == "NA"))
Final <- Final[Final$region_of_origin != "0",]
Final <- Final[Final$age_group != "",]

#Model, Logistic Regression
Final$region_of_origin <- suppressWarnings(as.factor(Final$region_of_origin))
Final$region_of_origin <- relevel(Final$region_of_origin, ref = "Mexico")
model <- glm(over_72_hours ~ year + gender + age_group + region_of_origin, data = Final)

#Convert to dataframe and print first 5 rows
Final_df <- Final %>% head()
```

### 2. Exploratory Data Analysis 

```{r}
#Exploratory Data Analysis 
Final$year %>% table()

Final$gender %>% table()

Final$age_group %>% table()

Final$region_of_origin %>% table()

Final$over_72_hours %>% table()
```
After exploring the dataset, the main takeaways are:

#### Year:

•	There are 63185 data points in 2017, 160608 in 2018, 279254 in 2019, and 9931 in 2020

#### Gender:

•	There are 313155 Male immigrants, 199823 Female immigrants

#### Age Group:

•	There are 13644 immigrants who are in Age Group 1 (0-1 years old), 
47213 in Age Group 2 (1-2 years old), 80051 in Age Group 3 (3-5 years old), 74062 in Age Group 4 (6-8 years old), 59164 in Age Group 5 (9-11 years old), 68686 in Age Group 6 (12-14 years old), 170158 in Age Group 7 (15-18 years old) 


#### Region of Origin: 

• There are 86667 immigrants from Mexico, 2196 from Europe, 4284 from Asia, 834 from Africa,
69 from Canada, 4280 from Caribbean, 390556 from Central America, 28 from the Middle East,
4 from Oceania, and 24060 from South America. 

#### Over 72 Hours: 

• There are 344594 immigrants who were kept less than 72 hours in an immigrant detention center. There are 168384 immigrants were were kept more than 72 hours in an immigrant detention center. 

### 3. Naive Bayes: Conditional Probabilites
```{r}
print(NBclassifier)
```


### 4. Decision Tree Classifier 

I created four balanced datasets. The first dataset was oversampled. The second was undersampled. The third was both under and over sampled. The last used the ROSE to generate data synethically. The Area under the Curve is ~0.62 for every dataset I made. 
```{r fig.width = 3, fig.height = 3,}
library(rpart)

#To Balance DataSet 

#OverSampling
data_balanced_over <- ovun.sample(over_72_hours ~ ., data = train, method = "over", 
                                  N = 482432)$data

#UnderSampling
data_balanced_under <- ovun.sample(over_72_hours ~ ., data = train, method = "under", 
                                   N = 235738, seed = 1)$data

#Both: Under and OverSampling
data_balanced_both <- ovun.sample(over_72_hours ~ ., data = train, method = "both", p=0.5, 
                                  N=1000, seed = 1)$data

#Rose: 
data_rose <- ROSE(over_72_hours ~., data = train, seed = 1)$data

#build decision tree models
tree.rose <- rpart(over_72_hours ~ ., data = data_rose)
tree.over <- rpart(over_72_hours ~ ., data = data_balanced_over)
tree.under <- rpart(over_72_hours ~ ., data = data_balanced_under)
tree.both <- rpart(over_72_hours ~ ., data = data_balanced_both)

#make predictions on data
pred.tree.rose <- predict(tree.rose, newdata = test)
pred.tree.over <- predict(tree.over, newdata = test)
pred.tree.under <- predict(tree.under, newdata = test)
pred.tree.both <- predict(tree.both, newdata = test)

#calculate accuracy of predictions
#65%

```


















